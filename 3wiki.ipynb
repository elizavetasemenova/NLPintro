{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1\n",
    "\n",
    "In this session, we will look at the wikileaks dataset and learn how to start gathering statistics about the dataset, preprocess the emails and extract useful information.\n",
    "\n",
    "https://en.wikipedia.org/wiki/2016_Democratic_National_Committee_email_leak\n",
    "https://wikileaks.org/dnc-emails/\n",
    "\n",
    "## DNC emails\n",
    "\n",
    "Around 40 000 emails leaked from DNC, around 1000 distinct users.\n",
    "\n",
    "I give you an already pre-processed dataset in .json, where the emails are a bit cleaned and put into a 'nice' structure. If you are interested in the process of crawling + generating this file, find me later or watch the repository: https://github.com/hanveiga/nlp-amld-2018\n",
    "\n",
    "\n",
    "Before we start:\n",
    "\n",
    "~~~\n",
    "sudo python3.6 -m spacy download en\n",
    "sudo python3.6 -m nltk.downloader all\n",
    "cd data\n",
    "curl https://www.dropbox.com/s/k16jptjyccxfdkn/clean_json.json?dl=0 -L -o clean_json.json\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading JSON file\n",
    "\n",
    "In the folder you will find a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_data = 'data/clean_json.json'\n",
    "\n",
    "def load_json_data(path_to_file):\n",
    "    data_DF = pd.read_json(path_to_file,encoding='ascii')\n",
    "    data_DF['from'] = data_DF['from'].str.lower()\n",
    "    data_DF['body'] = data_DF['body'].apply(lambda x: \" \".join(str(x).split()))\n",
    "    return data_DF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset from data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_json_data(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0:\n",
    "\n",
    "Quick exploration of the dataset\n",
    "\n",
    "How many users?   \n",
    "Who sends the most emails?    \n",
    "What are the most common words? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "\n",
    "Exploring one of the people in the dataset.\n",
    "\n",
    "For example, some names were particularly centered in the controversy, such as:\n",
    "\n",
    "\n",
    "Debbie Wasserman (email: hrtsleeve@gmail.com)    \n",
    "Brad Marshal (email: marshall@dnc.or)     \n",
    "Luis Miranda (mirandal@dnc.org) (he's just the top spammer :) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>from_name</th>\n",
       "      <th>subject</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>Good. Thanks everyone.</td>\n",
       "      <td>2016-05-06 15:29:08</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: Update</td>\n",
       "      <td>[[\"Miranda, Luis\", MirandaL@dnc.org]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10518</th>\n",
       "      <td>This is how he responds to Reid???</td>\n",
       "      <td>2016-05-17 19:11:55</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: FOR REVIEW: DNC Statement on Nevada Democr...</td>\n",
       "      <td>[[\"Miranda, Luis\", MirandaL@dnc.org], [, \"Banf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>Please refer the reporter to Luis Miranda, the...</td>\n",
       "      <td>2016-05-17 21:38:24</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: Platform Committee Inquiry</td>\n",
       "      <td>[[Greg Rosenbaum, greg@palisadesassociates.com]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10816</th>\n",
       "      <td>Damn liar. Particularly scummy that he barely ...</td>\n",
       "      <td>2016-05-17 14:38:09</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: Weaver on CNN re Nevada</td>\n",
       "      <td>[[\"Paustenbach, Mark\", PaustenbachM@dnc.org], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11281</th>\n",
       "      <td>We need to discuss the point of disagreement a...</td>\n",
       "      <td>2016-05-22 14:04:41</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: Platform Rollout Plan</td>\n",
       "      <td>[[Tracie Pough, PoughT@dnc.org]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11493</th>\n",
       "      <td>I am for the second one. What do others think?</td>\n",
       "      <td>2016-05-17 17:32:38</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: FOR REVIEW: DNC Statement on Nevada Democr...</td>\n",
       "      <td>[[\"Paustenbach, Mark\", PaustenbachM@dnc.org], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11782</th>\n",
       "      <td>No, I would not encourage them to do that. As ...</td>\n",
       "      <td>2016-05-12 02:25:18</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: Connecting you...</td>\n",
       "      <td>[[Erik Smith, erik@blueenginemedia.com], [, Lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>‎Good to go. No changes.</td>\n",
       "      <td>2016-05-17 23:34:49</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: FOR REVIEW: DWS statement about KY and OR ...</td>\n",
       "      <td>[[\"Miranda, Luis\", MirandaL@dnc.org]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12369</th>\n",
       "      <td>Excellent!</td>\n",
       "      <td>2016-04-29 23:50:56</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: The Hill - Sanders drops lawsuit against DNC</td>\n",
       "      <td>[[\"Miranda, Luis\", MirandaL@dnc.org], [, \"Dace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>I'm at a black tie dinner. Will quickly review...</td>\n",
       "      <td>2016-05-08 01:17:21</td>\n",
       "      <td>hrtsleeve@gmail.com</td>\n",
       "      <td>Debbie Wasserman Schultz</td>\n",
       "      <td>Re: Final Medium Post</td>\n",
       "      <td>[[Leah Daughtry, ldaughtry@demconvention.com],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body                date  \\\n",
       "10211                             Good. Thanks everyone. 2016-05-06 15:29:08   \n",
       "10518                 This is how he responds to Reid??? 2016-05-17 19:11:55   \n",
       "10560  Please refer the reporter to Luis Miranda, the... 2016-05-17 21:38:24   \n",
       "10816  Damn liar. Particularly scummy that he barely ... 2016-05-17 14:38:09   \n",
       "11281  We need to discuss the point of disagreement a... 2016-05-22 14:04:41   \n",
       "11493     I am for the second one. What do others think? 2016-05-17 17:32:38   \n",
       "11782  No, I would not encourage them to do that. As ... 2016-05-12 02:25:18   \n",
       "11946                           ‎Good to go. No changes. 2016-05-17 23:34:49   \n",
       "12369                                         Excellent! 2016-04-29 23:50:56   \n",
       "12652  I'm at a black tie dinner. Will quickly review... 2016-05-08 01:17:21   \n",
       "\n",
       "                      from                 from_name  \\\n",
       "10211  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "10518  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "10560  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "10816  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "11281  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "11493  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "11782  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "11946  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "12369  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "12652  hrtsleeve@gmail.com  Debbie Wasserman Schultz   \n",
       "\n",
       "                                                 subject  \\\n",
       "10211                                         Re: Update   \n",
       "10518  Re: FOR REVIEW: DNC Statement on Nevada Democr...   \n",
       "10560                     Re: Platform Committee Inquiry   \n",
       "10816                        Re: Weaver on CNN re Nevada   \n",
       "11281                          Re: Platform Rollout Plan   \n",
       "11493  Re: FOR REVIEW: DNC Statement on Nevada Democr...   \n",
       "11782                              Re: Connecting you...   \n",
       "11946  Re: FOR REVIEW: DWS statement about KY and OR ...   \n",
       "12369   Re: The Hill - Sanders drops lawsuit against DNC   \n",
       "12652                              Re: Final Medium Post   \n",
       "\n",
       "                                                      to  \n",
       "10211              [[\"Miranda, Luis\", MirandaL@dnc.org]]  \n",
       "10518  [[\"Miranda, Luis\", MirandaL@dnc.org], [, \"Banf...  \n",
       "10560   [[Greg Rosenbaum, greg@palisadesassociates.com]]  \n",
       "10816  [[\"Paustenbach, Mark\", PaustenbachM@dnc.org], ...  \n",
       "11281                   [[Tracie Pough, PoughT@dnc.org]]  \n",
       "11493  [[\"Paustenbach, Mark\", PaustenbachM@dnc.org], ...  \n",
       "11782  [[Erik Smith, erik@blueenginemedia.com], [, Lu...  \n",
       "11946              [[\"Miranda, Luis\", MirandaL@dnc.org]]  \n",
       "12369  [[\"Miranda, Luis\", MirandaL@dnc.org], [, \"Dace...  \n",
       "12652  [[Leah Daughtry, ldaughtry@demconvention.com],...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email =  \"hrtsleeve@gmail.com\"\n",
    "data[data[\"from\"]==email][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What words are the most emailed by this person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this does not say much. How can we improve? Stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "string_list = [a for a in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english') + string_list + ['Re','FWD', \"''\", \"``\",'...',\"-\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to get a feeling of what these people are talking about.\n",
    "\n",
    "In this example, we will do a simple topic mining model and use spacy to pick up on relevant entities.\n",
    "\n",
    "In particular:\n",
    "\n",
    "    Aggregate the communication between two people\n",
    "    Perform named entity extraction on the subset of emails\n",
    "\n",
    "The output of this task is to find pairs of people and the keywords/topics they are talking about in their emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "relevant_entities = ['EVENT','FAC','GPE','LAW','NORP','ORG','PRODUCT', 'PERSON']\n",
    "\n",
    "def get_keywords(sentence, ntop = 5):\n",
    "    if len(sentence) > 100000:\n",
    "        #going to truncate the sentence\n",
    "        sentence = sentence[0:100000]\n",
    "        \n",
    "    keywords = defaultdict(Counter)\n",
    "    doc = nlp(sentence)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in relevant_entities:\n",
    "            keywords[ent.label_][ent.text]+=1\n",
    "            \n",
    "    most_common_keywords = defaultdict(list)\n",
    "    \n",
    "    for key in keywords.keys():\n",
    "        most_common_keywords[key] = keywords[key].most_common(ntop)\n",
    "               \n",
    "    return most_common_keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last task\n",
    "\n",
    "Who has the most similar vocabulary?\n",
    "\n",
    "We use scikit learn for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember before we generated the word counts and user emails?\n",
    "# user_emails, word_count_body\n",
    "vocabulary_body_set = word_count_body.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
